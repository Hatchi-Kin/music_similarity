{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "import music_tag\n",
    "import numpy as np\n",
    "\n",
    "from music_utils import *\n",
    "\n",
    "from pymilvus import connections, utility\n",
    "from pymilvus import Collection, DataType, FieldSchema, CollectionSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid files: 174 | Number of invalid files: 0\n"
     ]
    }
   ],
   "source": [
    "DATASET = Path(\"Music_Dataset\")\n",
    "\n",
    "# check if the .pkl files are valid\n",
    "pkl_files = list(DATASET.rglob('*.pkl'))\n",
    "valid_files = [check_file_info(pkl_file) for pkl_file in pkl_files]\n",
    "print(f\"Number of valid files: {sum(valid_files)} | Number of invalid files: {len(valid_files) - sum(valid_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique types 87: {<class 'numpy.ndarray'>}\n",
      "Unique types 512: {<class 'numpy.ndarray'>}\n"
     ]
    }
   ],
   "source": [
    "types87 = []\n",
    "types512 = []\n",
    "\n",
    "for pkl_path in pkl_files:\n",
    "    with pkl_path.open('rb') as f:\n",
    "        try:\n",
    "            content = pickle.load(f)\n",
    "            embed = content.get('embedding_512')\n",
    "            if embed is not None:\n",
    "                types87.append(type(embed))\n",
    "                types512.append(type(embed))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {pkl_path}: {e}\")\n",
    "\n",
    "unique_types87 = set(types87)\n",
    "unique_types512 = set(types512)\n",
    "\n",
    "print(f\"Unique types 87: {unique_types87}\")\n",
    "print(f\"Unique types 512: {unique_types512}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: 08 Dub Pistols - Point Blank - Point Blank.mp3\n",
      "filepath: Music_Dataset/Dub_Pistols/08 Dub Pistols - Point Blank - Point Blank.mp3\n",
      "folder: Music_Dataset/Dub_Pistols\n",
      "filesize: 10.28\n",
      "title: Point Blank\n",
      "artist: Dub Pistols\n",
      "album: Point Blank\n",
      "year: 1998\n",
      "tracknumber: 8\n",
      "genre: Electronic\n",
      "predictions_87: [9.8139979e-04 2.0125259e-03 4.8705768e-03 2.5960850e-02 6.5091685e-03\n",
      " 5.3468816e-02 1.0176755e-03 5.2671704e-02 7.7658012e-03 1.0173839e-03\n",
      " 2.7207640e-04 7.1531860e-04 2.4420131e-02 2.5757801e-04 2.5672841e-04\n",
      " 1.9329896e-02 4.4482294e-04 3.4126728e-03 3.4647752e-04 2.7871925e-02\n",
      " 4.2696315e-04 1.1454568e-03 1.5394966e-01 1.8224511e-03 1.6941880e-03\n",
      " 6.3558104e-03 1.6666764e-02 1.2132645e-02 1.0800989e-02 4.7003655e-03\n",
      " 4.9221735e-03 4.0789612e-02 6.1270767e-03 7.0964789e-01 8.2458956e-03\n",
      " 3.1663079e-02 4.1977563e-03 9.9393986e-03 7.8052819e-02 1.3477497e-03\n",
      " 3.4186963e-02 7.5531667e-03 1.0674270e-02 4.0053626e-04 5.8707679e-03\n",
      " 1.5159677e-03 7.7537581e-02 6.8314813e-02 3.9541754e-03 2.0264906e-03\n",
      " 5.3086234e-03 2.2452308e-02 3.3720925e-02 7.5498489e-03 7.6403427e-03\n",
      " 1.1412381e-03 3.9516855e-03 3.0384958e-02 2.5514653e-04 5.2834474e-03\n",
      " 4.2203874e-03 6.6824430e-03 2.4685159e-03 2.7675335e-03 7.4033573e-02\n",
      " 1.8925956e-03 8.0037871e-03 5.6714029e-04 1.3671919e-02 6.9717159e-03\n",
      " 2.6791755e-03 3.3007592e-02 5.9379200e-03 7.9865903e-03 3.5450198e-02\n",
      " 8.3195721e-04 7.3551078e-04 5.0103990e-03 4.1966084e-02 1.7184659e-03\n",
      " 1.3877240e-03 1.7578544e-02 7.1196258e-02 2.6751086e-02 1.5694108e-02\n",
      " 2.7304797e-02 1.3239077e-02]\n",
      "embedding_512: [ 3.1627042   0.5854636   1.803329    3.4044373   1.8694601   1.3125105\n",
      "  1.249887    2.1832764   3.5954943   3.0100257   2.482623    4.688215\n",
      "  2.435927    1.6132627   2.166657    4.6425805   1.8265252   2.4343026\n",
      "  3.0632224   2.0245476   2.2320876   1.4992586   1.8289791   3.0427592\n",
      "  1.9106343   2.8224003   1.4733537   2.6892173   0.6805374   2.3587804\n",
      "  2.5429752   3.3063488   1.9346151   1.6835753   1.9688421   4.3765826\n",
      "  0.936038    1.8716873   2.1947722   3.4531286   3.7320232   3.7693691\n",
      "  2.5683424   2.8523762   1.0389237   4.0918503   3.7744043   1.3136013\n",
      "  1.5462195   2.8885565   2.0576355   2.0616255   1.9566977  -0.50027615\n",
      "  1.6739105   1.7409785   2.5593593   1.8596774   3.6786997   0.96231675\n",
      "  2.4058774   3.118557    1.7711283   2.6628516   1.4266772   2.6243804\n",
      "  2.251486    3.0408354   1.8359139   3.5235868   4.1141424   1.0681281\n",
      "  1.2520969   2.4872663   4.0461907   1.7547133   2.451499    2.008755\n",
      "  2.7821646   1.837202    1.3434612   1.8332368   1.5716811   0.5050993\n",
      "  1.7928866   3.1737516   3.1259897   4.2754183   2.0082757   3.3331332\n",
      "  2.8055222   4.229045    1.9295297   2.6097205   1.7660941   2.506174\n",
      "  4.0515995   1.8172959   1.495113    3.8387284   4.586141    1.9228659\n",
      "  0.68745416  2.5551617   3.7600982   2.2644987   1.9536301   4.72188\n",
      "  2.681331    1.1848668   1.3923774   1.7512294   4.7815156   1.1554061\n",
      "  2.779931    2.278698    0.57018656  1.557265    1.4342401   1.803343\n",
      "  2.3493629   3.320709    2.7751963   1.320755    2.6815808   1.938084\n",
      "  1.6090572   0.79626906  3.9818227   2.224159    1.7657512   1.4840553\n",
      "  2.8002307   2.2595603   2.8027754   1.0707303   2.3808537   1.4436882\n",
      "  2.4689624   3.4787836   2.227776    1.5996747   1.9852818   2.7857559\n",
      "  3.6758332   3.3342848   1.5613304   0.65538335  3.733098    1.4663378\n",
      "  2.1492844   5.1404934   1.4447838   2.5432708   2.207892    1.1229035\n",
      "  0.6300456   3.6847613   2.7415018   3.0897675   2.3723567   0.88575846\n",
      "  1.4416496   1.72977     2.2497358   1.7913542   0.63934463  2.6936746\n",
      "  3.5215852   1.3150368   1.5037386   1.3512927   2.6317196   2.1211405\n",
      "  2.8254874   2.9607997   1.9253838   1.4266471   1.8699418   2.022072\n",
      "  2.9059017   3.2963588   5.2044115   1.195545    0.39384583  2.3861265\n",
      "  2.3414593   5.2496223   3.556999    3.143481    3.467166    2.5236936\n",
      "  2.6253376   0.8645681   2.2261417   1.8142377   1.3947145   4.5829854\n",
      "  2.8049634   2.709873    1.7351103   4.151098    3.4431567   3.032806\n",
      "  2.0258489   3.42336     3.1411128   3.06793     2.7377229   0.8580898\n",
      "  0.22484264  0.94688135  1.5534328   2.986985    4.1059685   2.8991838\n",
      "  1.7773929   3.609452    3.8260717   2.7524595   0.95908624  1.5953681\n",
      "  0.28256908  2.2170696   3.0894732   2.3122246   1.3999308   2.823093\n",
      "  2.7743757   0.79750836  4.1775064   2.3009503   3.807187    1.5875949\n",
      "  2.5504267   1.2197279   1.639504    2.2163632   1.8198073   2.8202057\n",
      "  3.8299005   3.410905    3.7161324   2.0851102   0.8702799   2.410627\n",
      "  2.2122207   2.320842    3.2884774   2.2083051   3.5422447   1.8064771\n",
      "  1.6816252   3.9334872   2.2682362   2.949636    1.9350778   1.9430805\n",
      "  2.125233    2.0697792   1.2279168   1.306186    2.4710808   4.141793\n",
      "  1.622793    1.5494338   3.800916    4.0446835   1.8665782   1.9181616\n",
      "  4.782017    3.2601376   4.574651    3.4857836   1.7358308   3.001529\n",
      "  1.3210592   2.030347    2.8457954   1.7878158   2.0215063   1.2476276\n",
      "  3.8654666   3.477934    4.049083    2.630611    1.3861451   2.7768116\n",
      "  2.0196362   1.5293157   2.0117998   1.142201    2.5225036   0.9979958\n",
      "  1.5393214   1.4782293   2.4377546   4.480231    2.3216155   2.413696\n",
      "  2.2107086   2.3878245   1.8205311   2.517293    3.0187392   4.962961\n",
      "  2.3346732   2.6356995   2.153571    2.1651227   3.2800484   2.0992808\n",
      "  1.5736253   2.3114173   2.457448    2.59436     2.6075118   1.9497846\n",
      "  3.4903235   2.623668    3.5949235   2.4464896   2.876361    2.3346994\n",
      "  2.2635527   0.74739045  1.2118998   1.9759341   2.329489    2.8342853\n",
      "  2.819558    1.5796702   2.0691564   3.264758    3.2866876   1.5335208\n",
      "  2.6858869   1.576894    1.3761916   4.0542192   3.6672678   2.6588404\n",
      "  2.424881    2.5072076   1.7326956   2.6635487   0.7204385   2.894325\n",
      "  5.663339    2.7523758   4.797828    2.1277585   3.6170397   1.8745297\n",
      "  3.8049617   1.3455      2.4253647   3.4631376   2.4855564   1.9210609\n",
      "  0.9335946   0.63764185  2.202702    3.1054692   2.984248    3.648551\n",
      "  1.3990585   2.33477     1.381966    1.1165419   1.4171054   2.8245988\n",
      "  3.2129588   2.299605    3.0308647   5.424911    1.9652086   1.9359586\n",
      "  1.028554    2.42739     2.1625974   3.4091132   2.7193723   1.6483353\n",
      "  1.4007294   1.6830101   3.4229553   2.6445963   2.5896068   1.7806958\n",
      "  4.464008    2.2438116   2.802091    3.7010176   2.6991704   3.3202565\n",
      "  2.0891426   2.5502446   1.4184788   3.3742425   1.3123118   3.089366\n",
      "  2.4114592   3.0905235   5.3771186   2.4054372   0.9779842   3.9364903\n",
      "  3.1282775   4.07264     2.7900302   0.7778418   2.6288245   2.5388408\n",
      "  2.6681685   1.7328523   1.0959733   2.163627    1.2817317   1.9945927\n",
      "  2.8869987   1.1177217   2.1580784   1.4116675   1.9390998   1.6794399\n",
      "  1.9171592   1.9931375   1.8096797   2.0175226   2.4054024   1.7917609\n",
      "  4.2079487   2.3503358   3.025229    3.456202    1.3812482   1.0562415\n",
      "  0.9699725   2.2997642   4.8236437   3.2924032   1.6674408   2.4581108\n",
      "  2.8192606   0.77751946  1.0839547   2.1406736   3.8276193   1.4249548\n",
      "  1.3827157   2.3979146   2.055806    3.5092921   1.9288926   2.9501097\n",
      "  1.4176552   2.7757208   0.96457386  3.3917186   3.9567606   3.363632\n",
      "  2.6035466   2.2372046   2.2262006   1.9371955   3.4824085   3.2184072\n",
      "  0.9724038   2.3187077   2.3113518   3.103381    2.9388285   1.679733\n",
      "  2.124063    1.3021679   1.4594144   4.0050297   2.6306915   1.5566881\n",
      "  1.2874564   2.5195704   1.1501809   2.7895048   3.2290118   2.6662962\n",
      "  2.5711312   2.219961    2.5689924   2.7333102   1.970425    2.7944226\n",
      "  0.87503225  0.9985738   1.0670961   3.4005682   3.15603     2.811869\n",
      "  2.6364427   2.4031906   3.6085515   4.492367    3.1379871   2.7071028\n",
      "  1.962608    1.5156819   2.4778852   3.285209    1.8131001   1.4385278\n",
      "  2.143494    5.554091  ]\n",
      "top_5_genres: ['electronic', 'dance', 'experimental', 'hiphop', 'pop']\n"
     ]
    }
   ],
   "source": [
    "print_info(pick_random_mp3(DATASET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Milvus Client ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "URI = os.getenv(\"MILVUS_URI\")\n",
    "TOKEN = os.getenv(\"MILVUS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to milvus\n",
    "connections.connect(\"default\",\n",
    "                    uri=URI,\n",
    "                    token=TOKEN)\n",
    "print(f\"Connecting to DB: {URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## predictions_87 ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predictions_87', 'embeddings_512']\n"
     ]
    }
   ],
   "source": [
    "print(utility.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embeddings_512']\n"
     ]
    }
   ],
   "source": [
    "# Check if the collection exists\n",
    "check_collection_name = 'predictions_87'\n",
    "\n",
    "check_collection = utility.has_collection(check_collection_name )\n",
    "if check_collection:\n",
    "    drop_result = utility.drop_collection(check_collection_name )\n",
    "\n",
    "print(utility.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating example collection: predictions_87\n",
      "Schema: {'auto_id': False, 'description': '', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'path', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 280}}, {'name': 'title', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 220}}, {'name': 'artist', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 120}}, {'name': 'album', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 240}}, {'name': 'predictions', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 87}}, {'name': 'top_5_genres', 'description': '', 'type': <DataType.ARRAY: 22>, 'params': {'max_length': 100, 'max_capacity': 5}, 'element_type': <DataType.VARCHAR: 21>}], 'enable_dynamic_field': True}\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# create a collection for prediction_87\n",
    "collection_name = \"predictions_87\"\n",
    "dimension = 87\n",
    "\n",
    "# Define the schema\n",
    "schema = CollectionSchema(\n",
    "    fields=[\n",
    "        FieldSchema(name=\"id\",dtype=DataType.INT64,is_primary=True,auto_id=False,max_length=100),\n",
    "        FieldSchema(name=\"path\", dtype=DataType.VARCHAR, max_length=280),\n",
    "        FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=220),\n",
    "        FieldSchema(name=\"artist\", dtype=DataType.VARCHAR, max_length=120),\n",
    "        FieldSchema(name=\"album\", dtype=DataType.VARCHAR, max_length=240),\n",
    "        FieldSchema(name=\"predictions\", dtype=DataType.FLOAT_VECTOR, dim=dimension),\n",
    "        FieldSchema(name=\"top_5_genres\", dtype=DataType.ARRAY, element_type=DataType.VARCHAR, max_capacity=5, max_length=100),\n",
    "        ],\n",
    "    enable_dynamic_field=True,  # Optional, defaults to 'False'.\n",
    ")\n",
    "\n",
    "print(f\"Creating example collection: {collection_name}\")\n",
    "collection = Collection(collection_name, schema)\n",
    "print(f\"Schema: {schema}\")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='app.log', filemode='w', format='%(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def process_file(args):\n",
    "    i, path = args\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            filepath = data.get(\"filepath\")\n",
    "            title = data.get(\"title\")\n",
    "            album = data.get(\"album\")\n",
    "            artist = data.get(\"artist\")\n",
    "            predictions = data.get(\"predictions_87\")\n",
    "            top_5_genres = data.get(\"top_5_genres\")\n",
    "\n",
    "        if isinstance(predictions, np.ndarray):\n",
    "            return (i, filepath, title, album, artist, predictions, top_5_genres)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing file {path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 18 records into collection predictions_87.\n",
      "Inserted 36 records into collection predictions_87.\n",
      "Inserted 54 records into collection predictions_87.\n",
      "Inserted 72 records into collection predictions_87.\n",
      "Inserted 90 records into collection predictions_87.\n",
      "Inserted 108 records into collection predictions_87.\n",
      "Inserted 126 records into collection predictions_87.\n",
      "Inserted 144 records into collection predictions_87.\n",
      "Inserted 162 records into collection predictions_87.\n",
      "Inserted 180 records into collection predictions_87.\n"
     ]
    }
   ],
   "source": [
    "# Use a multiprocessing pool to process the files in parallel\n",
    "with Pool() as p:\n",
    "    results = p.map(process_file, enumerate(pkl_files))\n",
    "\n",
    "# Filter out None results\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "# Batch size\n",
    "batch_size = 18\n",
    "\n",
    "fails = []\n",
    "\n",
    "# Insert the data into the collection\n",
    "for i in range(0, len(results), batch_size):\n",
    "    id_batch, path_batch, title_batch, album_batch, artist_batch, predictions_batch, top_5_genres_batch = zip(*results[i : i + batch_size])\n",
    "    documents = [\n",
    "        {\n",
    "            \"id\": id,\n",
    "            \"path\": path,\n",
    "            \"title\": title,\n",
    "            \"album\": album,\n",
    "            \"artist\": artist,\n",
    "            \"predictions\": predictions.tolist(),\n",
    "            \"top_5_genres\": top_5_genres\n",
    "        }\n",
    "        for id, path, title, album, artist, predictions, top_5_genres in zip(\n",
    "            id_batch, path_batch, title_batch, album_batch, artist_batch, predictions_batch, top_5_genres_batch,\n",
    "        )\n",
    "    ]\n",
    "    try:\n",
    "        collection.insert(documents)\n",
    "        print(f\"Inserted {i + batch_size} records into collection {collection.name}.\")\n",
    "    except Exception as e:\n",
    "        fails.append((i + batch_size, documents))\n",
    "        print(f\"Error inserting batch {i + batch_size} into collection {collection.name}. Error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed batches: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed batches: {fails}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "collection.create_index(field_name=\"predictions\", index_params=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random mp3: Music_Dataset/Groundation/01_fight_all_you_can.pkl\n",
      "['reggae', 'dub', 'rock', 'world', 'pop']\n",
      "id: 93, distance: 0.007208452094346285, entity: {'path': 'Music_Dataset/Dub_Incorporation/04 - Rudeboy.mp3'}\n",
      "id: 69, distance: 0.008759484626352787, entity: {'path': 'Music_Dataset/Damian_Marley/06_-_Kingston_12.mp3'}\n",
      "id: 140, distance: 0.008851049467921257, entity: {'path': 'Music_Dataset/Groundation/03_Young_Tree.mp3'}\n",
      "id: 139, distance: 0.009532451629638672, entity: {'path': 'Music_Dataset/Groundation/02_Congress_Man.mp3'}\n",
      "id: 79, distance: 0.010738189332187176, entity: {'path': 'Music_Dataset/Doniki/01 My Bredren.mp3'}\n",
      "id: 78, distance: 0.013725015334784985, entity: {'path': 'Music_Dataset/Doniki/02 Eretrians.mp3'}\n",
      "id: 70, distance: 0.01601240038871765, entity: {'path': 'Music_Dataset/Damian_Marley/11_-_Me_Name_Jr._Gong.mp3'}\n",
      "id: 99, distance: 0.01986054889857769, entity: {'path': 'Music_Dataset/Rockamovya/01 - Take The Night.mp3'}\n",
      "id: 95, distance: 0.0212133526802063, entity: {'path': 'Music_Dataset/Dub_Incorporation/11 - Diversite.mp3'}\n",
      "id: 80, distance: 0.029756149277091026, entity: {'path': 'Music_Dataset/Doniki/11 Rock and groove.mp3'}\n"
     ]
    }
   ],
   "source": [
    "random_song = pick_random_mp3(DATASET).with_suffix(\".pkl\")\n",
    "print(f\"Random mp3: {random_song}\")\n",
    "print(get_top_5_genres(random_song, \"mtg_jamendo_genre.json\"))\n",
    "\n",
    "with open(random_song, \"rb\") as f:\n",
    "    file_info = pickle.load(f)\n",
    "    query_embed = file_info.get(\"predictions_87\")\n",
    "    \n",
    "search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\n",
    "result = collection.search([query_embed], \"predictions\", search_params, limit=10,offset=1, output_fields=[\"path\"])\n",
    "\n",
    "for element in result[0]:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## embedding_512 ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predictions_87', 'embeddings_512']\n"
     ]
    }
   ],
   "source": [
    "print(utility.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['predictions_87']\n"
     ]
    }
   ],
   "source": [
    "# Check if the collection exists\n",
    "check_collection_name = 'embeddings_512'\n",
    "\n",
    "check_collection = utility.has_collection(check_collection_name )\n",
    "if check_collection:\n",
    "    drop_result = utility.drop_collection(check_collection_name )\n",
    "\n",
    "print(utility.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating example collection: embeddings_512\n",
      "Schema: {'auto_id': False, 'description': '', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'path', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 280}}, {'name': 'title', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 220}}, {'name': 'album', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 240}}, {'name': 'artist', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 120}}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 512}}, {'name': 'top_5_genres', 'description': '', 'type': <DataType.ARRAY: 22>, 'params': {'max_length': 100, 'max_capacity': 5}, 'element_type': <DataType.VARCHAR: 21>}], 'enable_dynamic_field': True}\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# create a collection for embeddings_512\n",
    "collection_name = \"embeddings_512\"\n",
    "dimension = 512\n",
    "\n",
    "# Define the schema\n",
    "schema = CollectionSchema(\n",
    "    fields=[\n",
    "        FieldSchema(name=\"id\",dtype=DataType.INT64,is_primary=True,auto_id=False,max_length=100),\n",
    "        FieldSchema(name=\"path\", dtype=DataType.VARCHAR, max_length=280),\n",
    "        FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=220),\n",
    "        FieldSchema(name=\"album\", dtype=DataType.VARCHAR, max_length=240),\n",
    "        FieldSchema(name=\"artist\", dtype=DataType.VARCHAR, max_length=120),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dimension),\n",
    "        FieldSchema(name=\"top_5_genres\",dtype=DataType.ARRAY,element_type=DataType.VARCHAR,max_capacity=5,max_length=100),\n",
    "    ],\n",
    "    enable_dynamic_field=True,  # Optional, defaults to 'False'.\n",
    ")\n",
    "\n",
    "print(f\"Creating example collection: {collection_name}\")\n",
    "collection = Collection(collection_name, schema)\n",
    "print(f\"Schema: {schema}\")\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(args):\n",
    "    i, path = args\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            filepath = data.get(\"filepath\")\n",
    "            title = data.get(\"title\")\n",
    "            album = data.get(\"album\")\n",
    "            artist = data.get(\"artist\")\n",
    "            predictions = data.get(\"embedding_512\") #\n",
    "            top_5_genres = data.get(\"top_5_genres\")\n",
    "\n",
    "        if isinstance(predictions, np.ndarray):\n",
    "            return (i, filepath, title, album, artist, predictions, top_5_genres)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing file {path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 18 records into collection embeddings_512.\n",
      "Inserted 36 records into collection embeddings_512.\n",
      "Inserted 54 records into collection embeddings_512.\n",
      "Inserted 72 records into collection embeddings_512.\n",
      "Inserted 90 records into collection embeddings_512.\n",
      "Inserted 108 records into collection embeddings_512.\n",
      "Inserted 126 records into collection embeddings_512.\n",
      "Inserted 144 records into collection embeddings_512.\n",
      "Inserted 162 records into collection embeddings_512.\n",
      "Inserted 180 records into collection embeddings_512.\n"
     ]
    }
   ],
   "source": [
    "# Use a multiprocessing pool to process the files in parallel\n",
    "with Pool() as p:\n",
    "    results = p.map(process_file, enumerate(pkl_files))\n",
    "\n",
    "# Filter out None results\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "# Batch size\n",
    "batch_size = 18\n",
    "\n",
    "fails = []\n",
    "\n",
    "# Insert the data into the collection\n",
    "for i in range(0, len(results), batch_size):\n",
    "    id_batch, path_batch, title_batch, album_batch, artist_batch, embeddings_batch, top_5_genres_batch = zip(*results[i : i + batch_size])\n",
    "    documents = [\n",
    "        {\n",
    "            \"id\": id,\n",
    "            \"path\": path,\n",
    "            \"title\": title,\n",
    "            \"album\": album,\n",
    "            \"artist\": artist,\n",
    "            \"embedding\": embeddings.tolist(),\n",
    "            \"top_5_genres\": top_5_genres\n",
    "        }\n",
    "        for id, path, title, album, artist, embeddings, top_5_genres in zip(\n",
    "            id_batch, path_batch, title_batch, album_batch, artist_batch, embeddings_batch, top_5_genres_batch,\n",
    "        )\n",
    "    ]\n",
    "    try:\n",
    "        collection.insert(documents)\n",
    "        print(f\"Inserted {i + batch_size} records into collection {collection.name}.\")\n",
    "    except Exception as e:\n",
    "        fails.append((i + batch_size, documents))\n",
    "        print(f\"Error inserting batch {i + batch_size} into collection {collection.name}. Error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed batches: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed batches: {fails}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random mp3: Music_Dataset/Sofi_tukker/Sofi Tukker - awoo.pkl\n",
      "['electronic', 'house', 'dance', 'pop', 'ambient']\n",
      "\n",
      "\n",
      "id: 12, distance: 81.15666961669922, entity: {'path': 'Music_Dataset/Les_Blaireaux/13 Berlin.mp3'}\n",
      "id: 13, distance: 87.51583862304688, entity: {'path': 'Music_Dataset/Les_Blaireaux/07 Natalia Poutine.mp3'}\n",
      "id: 52, distance: 94.92430877685547, entity: {'path': 'Music_Dataset/Massive_Attack/Massive_Attack_-_Blue_Lines_-01-_Safe_from_Harm.mp3'}\n",
      "id: 18, distance: 96.50566101074219, entity: {'path': 'Music_Dataset/Major_Lazer/03 Major Lazer - Get Free (feat. Amber of Dirty Projectors).mp3'}\n",
      "id: 159, distance: 97.5042495727539, entity: {'path': 'Music_Dataset/A_Tribe_Called_Quest/01_Push_It_Along.mp3'}\n",
      "id: 116, distance: 99.24071502685547, entity: {'path': 'Music_Dataset/Birdy_Nam_Nam/15 Abbesses.mp3'}\n",
      "id: 67, distance: 100.14732360839844, entity: {'path': 'Music_Dataset/Adele/01 Adele - Rolling In The Deep.mp3'}\n",
      "id: 51, distance: 102.6116943359375, entity: {'path': 'Music_Dataset/Massive_Attack/Massive_Attack_-_Blue_Lines_-09-_Hymn_of_the_Big_Wheel.mp3'}\n",
      "id: 147, distance: 105.03129577636719, entity: {'path': 'Music_Dataset/Jack_Johnson/03_Traffic_in_the_Sky_320kbps.mp3'}\n",
      "id: 168, distance: 105.22247314453125, entity: {'path': 'Music_Dataset/Moriarty/04-moriarty-motel.mp3'}\n"
     ]
    }
   ],
   "source": [
    "random_song = pick_random_mp3(DATASET).with_suffix(\".pkl\")\n",
    "print(f\"Random mp3: {random_song}\")\n",
    "print(get_top_5_genres(random_song, \"mtg_jamendo_genre.json\"))\n",
    "\n",
    "with open(random_song, \"rb\") as f:\n",
    "    file_info = pickle.load(f)\n",
    "    query_embed = file_info.get(\"embedding_512\")\n",
    "    \n",
    "search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\n",
    "result = collection.search([query_embed], \"embedding\", search_params, limit=10, offset=1, output_fields=[\"path\"])\n",
    "print('\\n')\n",
    "for element in result[0]:\n",
    "    print(element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
